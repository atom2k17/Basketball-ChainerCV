# -*- coding: utf-8 -*-
"""BasketballComplete.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jxL4JqI6TUP--4J7sBw_yfP41W11tW3W
"""

from google.colab import files
uploaded = files.upload()

"""Unzip the uploaded zipped dataset using command prompt command."""

!unzip NewDataset.zip

!pip install chainercv

import chainercv
import os
import xml.etree.ElementTree as ET
from chainercv.datasets import VOCBboxDataset
import numpy as np

"""Now we will create a Dataset creating class. This class is going to read the train,val,test text files and the annotation files. It will assign the number of images in train, val and test set and get image data, bbox data and label data."""

bball_labels = ('ball','player')
class Dataset_Creator(VOCBboxDataset):
  def _get_annotations(self, i):
    id_ = self.ids[i]
    anno = ET.parse(os.path.join(self.data_dir, 'Annotations', id_ + '.xml'))
    bbox = []
    label = []
    difficult = []
    for obj in anno.findall('object'):
      bndbox_anno = obj.find('bndbox')
      bbox.append([int(bndbox_anno.find(tag).text) - 1 for tag in ('ymin', 'xmin', 'ymax', 'xmax')])
      name = obj.find('name').text.lower().strip()
      label.append(bball_labels.index(name))
    bbox = np.stack(bbox).astype(np.float32)
    label = np.stack(label).astype(np.int32)
    difficult = np.array(difficult, dtype=np.bool)
    return bbox, label, difficult

valid_dataset = Dataset_Creator('NewDataset', 'val')
test_dataset = Dataset_Creator('NewDataset', 'test')
train_dataset = Dataset_Creator('NewDataset', 'train')

print('Number of images in "train" dataset:', len(train_dataset))
print('Number of images in "valid" dataset:', len(valid_dataset))
print('Number of images in "test" dataset:', len(test_dataset))

# %matplotlib inline
from chainercv.visualizations import vis_bbox

img, bbox, label = train_dataset[0]
ax = vis_bbox(img, bbox, label, label_names=bball_labels)
ax.set_axis_off()
ax.figure.tight_layout()

"""The code below downloads the pre-trained weights of SSD300 model trained on ImageNet dataset."""

import copy
import numpy as np

import chainer
from chainer.datasets import TransformDataset
from chainer.optimizer import WeightDecay
from chainer import serializers
from chainer import training
from chainer.training import extensions
from chainer.training import triggers

from chainercv.extensions import DetectionVOCEvaluator
from chainercv.links.model.ssd import GradientScaling
from chainercv.links.model.ssd import multibox_loss
from chainercv.links import SSD300
from chainercv import transforms

from chainercv.links.model.ssd import random_crop_with_bbox_constraints
from chainercv.links.model.ssd import random_distort
from chainercv.links.model.ssd import resize_with_random_interpolation


class MultiboxTrainChain(chainer.Chain):

    def __init__(self, model, alpha=1, k=3):
        super(MultiboxTrainChain, self).__init__()
        with self.init_scope():
            self.model = model
        self.alpha = alpha
        self.k = k

    def __call__(self, imgs, gt_mb_locs, gt_mb_labels):
        mb_locs, mb_confs = self.model(imgs)
        loc_loss, conf_loss = multibox_loss(
            mb_locs, mb_confs, gt_mb_locs, gt_mb_labels, self.k)
        loss = loc_loss * self.alpha + conf_loss

        chainer.reporter.report(
            {'loss': loss, 'loss/loc': loc_loss, 'loss/conf': conf_loss},
            self)

        return loss
      
model = SSD300(n_fg_class=len(bball_labels), pretrained_model='imagenet')
train_chain = MultiboxTrainChain(model)

batchsize = 32
gpu_id = 0
out = 'results'
initial_lr = 0.001
training_epoch = 300
log_interval = 10, 'epoch'
lr_decay_rate = 0.1
lr_decay_timing = [200, 250]

"""Transform class is for augmenting the dataset into a larger dataset and more variations. Here it does 5 kinds of augmentation."""

class Transform(object):

    def __init__(self, coder, size, mean):
        # to send cpu, make a copy
        self.coder = copy.copy(coder)
        self.coder.to_cpu()

        self.size = size
        self.mean = mean

    def __call__(self, in_data):
        # There are five data augmentation steps
        # 1. Color augmentation
        # 2. Random expansion
        # 3. Random cropping
        # 4. Resizing with random interpolation
        # 5. Random horizontal flipping

        img, bbox, label = in_data

        # 1. Color augmentation
        img = random_distort(img)

        # 2. Random expansion
        if np.random.randint(2):
            img, param = transforms.random_expand(
                img, fill=self.mean, return_param=True)
            bbox = transforms.translate_bbox(
                bbox, y_offset=param['y_offset'], x_offset=param['x_offset'])

        # 3. Random cropping
        img, param = random_crop_with_bbox_constraints(
            img, bbox, return_param=True)
        bbox, param = transforms.crop_bbox(
            bbox, y_slice=param['y_slice'], x_slice=param['x_slice'],
            allow_outside_center=False, return_param=True)
        label = label[param['index']]

        # 4. Resizing with random interpolatation
        _, H, W = img.shape
        img = resize_with_random_interpolation(img, (self.size, self.size))
        bbox = transforms.resize_bbox(bbox, (H, W), (self.size, self.size))

        # 5. Random horizontal flipping
        img, params = transforms.random_flip(
            img, x_random=True, return_param=True)
        bbox = transforms.flip_bbox(
            bbox, (self.size, self.size), x_flip=params['x_flip'])

        # Preparation for SSD network
        img -= self.mean
        mb_loc, mb_label = self.coder.encode(bbox, label)

        return img, mb_loc, mb_label

chainer.cuda.set_max_workspace_size(1024 * 1024 * 1024)
chainer.config.autotune = True

"""Creating Iterators for training. The Transform function is used on train_dataset."""

transformed_train_dataset = TransformDataset(train_dataset, Transform(model.coder, model.insize, model.mean))

train_iter = chainer.iterators.MultiprocessIterator(transformed_train_dataset, batchsize)
valid_iter = chainer.iterators.SerialIterator(valid_dataset, batchsize, repeat=False, shuffle=False)

optimizer = chainer.optimizers.MomentumSGD()
optimizer.setup(train_chain)
for param in train_chain.params():
    if param.name == 'b':
        param.update_rule.add_hook(GradientScaling(2))
    else:
        param.update_rule.add_hook(WeightDecay(0.0005))

updater = training.updaters.StandardUpdater(
    train_iter, optimizer, device=gpu_id)

trainer = training.Trainer(
    updater,
    (training_epoch, 'epoch'), out)

trainer.extend(
    extensions.ExponentialShift('lr', lr_decay_rate, init=initial_lr),
    trigger=triggers.ManualScheduleTrigger(lr_decay_timing, 'epoch'))

trainer.extend(
    DetectionVOCEvaluator(
        valid_iter, model, use_07_metric=False,
        label_names=bball_labels),
    trigger=(1, 'epoch'))
trainer.extend(extensions.LogReport(trigger=log_interval))
trainer.extend(extensions.observe_lr(), trigger=log_interval)
trainer.extend(extensions.PrintReport(
    ['epoch', 'iteration', 'lr',
     'main/loss', 'main/loss/loc', 'main/loss/conf',
     'validation/main/map', 'elapsed_time']),
    trigger=log_interval)
if extensions.PlotReport.available():
    trainer.extend(
        extensions.PlotReport(
            ['main/loss', 'main/loss/loc', 'main/loss/conf'],
            'epoch', file_name='loss.png'))
    trainer.extend(
        extensions.PlotReport(
            ['validation/main/map'],
            'epoch', file_name='accuracy.png'))
trainer.extend(extensions.snapshot(
    filename='snapshot_epoch_{.updater.epoch}.npz'), trigger=(10, 'epoch'))

trainer.run()

"""Here we are detecting the 2 classes in the image with bounding boxes. Along with it, it will display the class name and the accuracy for that particular prediction. It also displays the count for each class."""

import collections
from chainercv import utils
from chainercv.visualizations.colormap import voc_colormap
from chainercv.visualizations import vis_bbox
import matplotlib.pyplot as plt

img = utils.read_image('NewDataset/JPEGImages/img1 res.jpg', color=True)
bboxes, labels,scores = model.predict([img])
bbox, label, score = bboxes[0], labels[0], scores[0]
colors = voc_colormap(label + 1)
vis_bbox(img, bbox, label, score*100, label_names=bball_labels, instance_colors=colors, alpha=0.9, linewidth=2.0)


def CountFrequency(arr):
   return collections.Counter(arr)

# Driver function
if __name__ == "__main__":
  arr = label
  freq = CountFrequency(arr)

   # iterate dictionary named as freq to print
   # count of each element
  for key, value in freq.items():
    if key==0:
      b='ball' 
      i=value
    if key==1:
      b='player'
      j=value
    print(b, " -> ", value)
  tot = i+j
  ball = i/tot*100
  player = j/tot*100
plt.show()
print("ball Percentage:",str(round(ball,2)))
print("player Percentage:",str(round(player,2)))